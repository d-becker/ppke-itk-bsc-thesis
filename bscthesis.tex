\documentclass[fontsize=11pt, appendixprefix=true]{scrreprt}
\usepackage[magyar, english]{babel}                        % nyelvi csomag
\usepackage[T1]{fontenc}                                   % ékezetes betűknél is legyen automatikus elválasztás
\usepackage[utf8]{inputenc}                                % ékezetes betűk kezelése
\usepackage{lmodern}                                       % alapértelmezett betűtípus ne legyen pixeles
\usepackage{mathtools}                                     % képletekhez kell
\usepackage[style=ieee, backend=biber]{biblatex}           % bibliográfia
\usepackage{graphicx}                                      % képek beszúrása
\graphicspath{ {./images/} }
\usepackage[export]{adjustbox}                             % ez az ITK logó pozicionálásához kell
\usepackage[margin=2.5cm, bindingoffset=1.25cm]{geometry}  % margók
\usepackage[onehalfspacing]{setspace}                      % másfeles sorköz
\usepackage[hidelinks, unicode, pdfusetitle]{hyperref}     % kattintható tartalomjegyzék és hivatkozások
\usepackage{bookmark}                                      % PDF könyvjelzők
\usepackage{csquotes}                                      % a bibliográfiában megfelelően legyenek formázva az idézőjelek
%% \DeclareQuoteAlias{dutch}{magyar}

% Kódrészletekhez ajánlom
\usepackage{listings, scrhack}
\usepackage{sourcecodepro} % egy jó betűtípus
\lstset{captionpos=b, numberbychapter=false, basicstyle=\ttfamily, showstringspaces=false, columns=fullflexible}
%% \renewcommand\lstlistingname{kódrészlet}
\makeatletter
\renewcommand\fnum@lstlisting{\ifx\lst@@caption\@empty\else\thelstlisting.~\fi\lstlistingname}%
\makeatother

\titlehead{\includegraphics[valign=m]{ITK_logo} \parbox[c]{\textwidth}{Pázmány Péter Catholic University\\Faculty of Information Technology and Bionics}}
\subject{Thesis}
\addbibresource{bscthesis.bib}

\author{Dániel Balázs Becker\\Computer Science Engineering BSc}
\title{Abstracting Multimaterial Data Structures And Algorithms}
\date{2018}
\publishers{Supervisor:\\István Zoltán Reguly, PhD}

% Nyilatkozathoz két parancs definíciója
\newcommand{\pushtobottom}{\vspace*{\fill}}
\newcommand{\signatureline}[1]{\begin{flushright}
	\vspace*{.5cm}\par\noindent\makebox[2.5in]{\hrulefill}
	\par\noindent\makebox[2.5in][c]{#1}
	\end{flushright}
}

\begin{document}
\maketitle

\pushtobottom
I, undersigned Dániel Balázs Becker, student of the Faculty of
Information Technology and Bionics at Pázmány Péter Catholic University, declare
that I have written this thesis solely myself, without any unauthorized
help, and I have only used the sources referenced. Every part quoted word by
word or in a paraphrased manner is indicated clearly, with a reference made. I
have not submitted this thesis in any other training program.
\signatureline{Signature}

\tableofcontents
\newpage
\section*{Abstract}
Computations based on a structured or unstructured mesh, with the possibility of
accessing neighbouring elements, have wide-ranging applications in scientific
computing. Examples include fluid dynamics simulations, simulation of cellular
automata and the solution of partial differential equations (PDEs). As such,
there are innumerable implementations done by scientists and programmers both
for one-off experiments and for large software used in production. In many
cases, the computational performance achieved by such codes is vital for
scientific exploration, therefore many utilise modern many-core architectures
such as multi-core CPUs or GPUs.

Today's wide variety of modern many-core architectures, with their differing
programming styles, requires considerable programming effort to run applications
efficiently, making full use of the features and characteristics of the
available hardware. The programmer has to consider several levels of
parallelism; even CPUs now include wide vector units in each core, as well as
multiple cores, and various highly parallel hardware architectures such as GPUs
or FPGAs can be used either in addition to or instead of CPUs. The complex
memory hierarchies that often involve several levels of cache, which may be
explicitly programmable, present another difficulty as the programmer has to
take cache behaviour into account in order to make the code efficient.

If a certain piece of code needs to run well on multiple architectures, the
coding effort is multiplied, and subsequently maintenance is more difficult as
well --- any modification has to be applied to multiple codebases.

In my thesis we are working on an abstraction for describing such computations
at a high level, allowing fast experimentation and productivity. The abstraction
is designed in such a way that it can be automatically converted to various
high-performance implementations.

A critical feature of this abstraction is an extension to support a varying
number of materials, or species, at each grid point in the mesh, enabling much
more complex simulations. After examining real-world multimaterial computation
use cases, it becomes clear that devising a scheme that handles these
computations efficiently (both in terms of memory usage and speed) is
non-trivial. The main reason is that in most cases the vast majority of the mesh
cells only contain one material, which opens up the possibility for using more
economical (both in terms of memory and speed), compressed sparse data
structures to store the data.

In this work, we present the abstraction, which comes in the form of an Embedded
Domain Specific Language (eDSL) or ``active library'', the host language being
C++. This means that the framework can be used as if it were a traditional
software library and can be compiled with normal compilers, but the intended
usage for production applications is to use source-to-source compilation,
generating code specifically to take advantage of the target hardware
architecture. We also present examples of the most important computational
patterns implemented in our framework, both single material and multimaterial
cases.

\newpage
\section*{Kivonat}
\begin{otherlanguage}{magyar}
A strukturált és nemstrukturált térhálókon értelmezett, szomszédos elemek
elérését lehetővé tevő számítási minták nagyon gyakoriak a tudományos célú
számítógépes szimulációkban, többek között fluidikai szimulációk, celluláris
automaták szimulációja és parciális differenciálegyenletek megoldása
esetén. Ennek következtében mind kutatók, mind programozók számtalan
implementációt készítettek az ilyen típusú számítások elvégzésére, mind egyszeri
kísérletek céljából, mind nagyobb, tartós használatra készült programok
részeként. A programok számítási teljesítménye nagy jelentőséggel bír a
tudományos kutatásban való és egyéb felhasználás során, ezért sok implementáció
használ modern, többmagos architektúrákat, például többmagos CPU-kat és GPU-kat.

A ma elérhető modern, többmagos architektúrák sokfélesége jelentős programozói
erőfeszítést tesz szükségessé, mivel a különböző hardvereket különböző módokon
kell programozni, kiváltképp, ha a program hatékonyságának növelése érdekében az
eszköz tulajdonságait a lehető legnagyobb mértékben ki szeretnénk használni. A
párhuzamosságnak több szintjére kell odafigyelni: a modern CPU-k mindegyik magja
tartalmaz vektorizációs egységeket, a processzorok több magból állnak, és a
CPU-k helyett vagy mellett használhatunk nagyfokú párhuzamosságra képes
eszközöket is, például GPU-kat vagy FPGA-kat. A komplex, hierarchikus
memóriaarchitektúrák, amelyek több, akár explicite programozható cache-szintet
tartalmaznak, egy újabb nehézséget jelentenek a programozó számára, mivel
figyelembe kell vennie a cache sajátosságait ahhoz, hogy hatékony, a memóriát
jól használó programot írjon.

Ha egy adott kódnak többféle architektúrán kell hatékonyan futnia, a szükséges
programozási munka mennyisége is megsokszorozódik, és ennek következtében a
kódbázis karbantartása is sokkal nehezebbé válik, mivel minden változtatást több
helyen is végre kell hajtani.

A szakdolgozatom kapcsán egy olyan absztrakció létrehozásán dolgozunk, amivel a
fent leírt számítási minták könnyen, magas szinten leírhatók, lehetővé téve a
produktív, gyors kísérletezést. Az absztrakciót olyan módon terveztük meg, hogy
lehetőség legyen belőle különböző hardverarchitektúrákra optimalizált kódot
generálni automatikusan.

Az absztrakció egyik legjelentősebb eleme, hogy a térháló minden pontjában
egyszerre több anyag is jelen lehet, amivel sokkal komplexebb szimulációk
futtatása válik lehetségessé. A már létező több anyagos szimulációk vizsgálata
során egyértelművé vált, hogy egy olyan absztrakció kidolgozása, amely az ilyen
számításokat mind memóriahasználat, mind futási sebesség szempontjából
hatékonyan tudja elvégezni, nem triviális. Ennek oka az, hogy a legtöbb
szimulációban a cellák túlnyomó többsége mindössze egy anyagot tartalmaz, ezért
lehetőség nyílik a memóriahasználat és a futásidő tekintetében is gazdaságosabb,
tömörített ritka adatstruktúrák használatára.

Ezen szakdolgozatban bemutatjuk a megtervezett absztrakciót, amit egy a C++
programozási nyelvbe beágyazott domain-specifikus nyelv (eDSL) formájában
valósítunk meg. Ez azt jelenti, hogy a keretrendszer használható hagyományos
szoftverkönyvtárként, és a megírt kód lefordítható hagyományos C++ fordítókkal
is, de alapvetően a cél az egyes architektúrák sajátosságait hatékonyan
kihasználó kód automatikus generálása minden támogatott hardverarchitektúrára.
Az absztrakció ismertetése után bemutatjuk a legfontosabb számítási minták
implementációját a leírt absztrakció segítségével, mind egy anyagos, mind több
anyagos példákkal illusztrálva az keretrendszer használatának lehetőségeit.
\end{otherlanguage}

\chapter{Introduction}

In computational simulations in various scientific fields, the class of problems
that can be addressed by a model containing a spatial mesh, with data defined on
its cells and possibly also its edges, has proven to be very useful. Examples of
its use cases include computational fluid dynamics (CFD), computational
electro-magnetics (CEM), the simulation of cellular automata as well as the
solution of partial differential equations (PDEs).

In this chapter, we give a description of the challenges faced by programmers or
scientists who aim to make use of this computational model while trying to
utilise the full potential of the vast array of modern, parallel hardware
architectures available today. We describe how a high level abstraction can help
to overcome these difficulties without undue compromises in performance. We also
give an overview of existing approaches to this problem, and show in what ways
our proposed abstraction differs from these or extends them.

\section{Description of the problem}

\subsection{Structured vs. unstructured meshes}
\begin{figure}
    \centering
    \includegraphics[width=0.25\textwidth]{structured_mesh}
    \caption{Structured Cartesian grid in 3D}
    \label{fig:structured_mesh}

    \small Source: By Mysid, Slffea - Drawn in CorelDraw by Mysid, based on a %
    JPEG by Slffea., CC BY-SA 3.0 %
    https://commons.wikimedia.org/w/index.php?curid=1367845
\end{figure}

In the classification of mesh types, we differentiate between structured and
unstructured meshes. The simpler of the two types is that of structured meshes
--- the neighbourhood relations between the mesh cells are regular and are known
from the arrangement of the data in memory. The most straightforward example is
a rectangular (or even square) mesh in two dimensions, where the cells are
identical rectangles or squares. If we store the data in a two dimensional
array, the neighbours of a cell can easily be calculated by adding or
subtracting one (or any other number in case of broader neighbourhoods) from the
row and column indices of the cell. Structured meshes are very efficient in
terms of memory usage and computational performance, as neighbourhood
information is implicit in the storage pattern of the data, and no additional
connectivity information needs to be stored or looked up. An example of a
three-dimensional structured Cartesian grid is shown in
\autoref{fig:structured_mesh}.

Unstructured meshes, on the other hand, exhibit irregular connectivity between
the cells. The shape of the cells is often triangular in two dimensions (and
tetrahedral in three dimensions), though other shapes are also possible. Storing
the data in multidimensional arrays is not convenient as information about which
cells are adjacent needs to be stored explicitly, taking up space, and
necessitating more expensive lookup routines than simple integer arithmetics. On
the other hand, in settings where the solution varies across a large dynamic
range, it is often advantageous to have different resolutions in different parts
of the space, which can be accomplished easily with an unstructured mesh, in
contrast to a structured one. An example of a two-dimensional unstructured mesh
is shown in \autoref{fig:unstructured_mesh}.

\begin{figure}
    \centering
    \includegraphics[width=0.25\textwidth]{unstructured_mesh}
    \caption{Unstructured grid in 2D}
    \label{fig:unstructured_mesh}

    \small Source: By I, Zureks, CC BY-SA 3.0, %
    https://commons.wikimedia.org/w/index.php?curid=2358783
\end{figure}

Therefore, if the problem at hand lends itself to being modelled with structured
meshes, a more efficient solution can be achieved if we take advantage of the
structure. However, not all problems are easily described in terms of structured
meshes, making it necessary to consider unstructured ones as well. In some
cases, it may also be useful to build hybrid meshes that contain structured and
unstructured parts, leveraging the efficiency of structured meshes where the
geometry of the problem allows it, while using an unstructured topology where it
is necessary.

\subsection{Challenges}
In the past decades, numerous parallel hardware architectures have emerged and
become available for scientific research. The programming models of these are
often inherently different. CPUs, GPUs and FPGAs have varying degrees and
underlying physical implementations of parallelism. As an example, modern CPUs
contain multiple cores, but in each core, they usually also have vectorisation
units for the \textit{Single instruction, multiple data (SIMD)} type of
parallelism. This variability implies that in order to make full use of all of
their features and characteristics, these architectures need to be programmed in
potentially very different ways.

Another difficulty that has become relevant comparatively recently is the use of
hierarchical cache architectures. The need for those arises because the increase
in RAM speed has not generally been able to keep up with the pace of the
increase in processing speed. Therefore, more and more often the bottleneck in a
computation is not caused by the processing time but by waiting for data I/O.

Hierarchical cache architectures consist of multiple layers of memory storage
units organised such that higher-speed storage elements, which are often also
located closer to the processing unit, have lower storage capacity than
lower-speed elements. Main memory itself could be regarded as the last layer of
this hierarchy (if we do not consider hard disk drives or solid state drives),
having the highest storage capacity and the lowest speed. Efficient usage of the
cache hierarchy is vital in many applications, as accessing data from main
memory or from a slower cache level is potentially orders of magnitude slower
than accessing data in a high-speed cache unit. On many architectures,
manufacturers employ complex intelligent algorithms implemented within the
hardware that facilitate optimal cache usage, but still, writing software in a
cache-friendly way often has enormous impact on performance --- indeed,
cache-friendly programming often essentially means writing software in a way
that presents data to the processor such the its hardware cache algorithms can
be as efficient as possible. Most of the time it means that data regions that
are accessed close in time should be located close in memory. This is because
when the processor reads from memory, it always reads a fixed amount of data
even if it is more than what is immediately required. If the remaining data is
the same as is needed by the next computation cycle, it makes it unnecessary to
perform another (potentially very expensive) load operation from memory.

Scientific computations are often run on different parallel hardware devices to
speed up the simulations and make scientific experimentation faster. However,
programmers and scientists face a great challenge if they, because of the
differences in programming models and memory characteristics, have to maintain
separate code bases for each architecture. To write efficient code for these
devices, deep low-level knowledge of them is necessary and the scientists
needing to use them are usually not experts on any of these architectures and
definitely not several of them. Furthermore, maintenance of the code also
becomes more difficult, as any change introduced has to be applied to multiple
parts of the code base.

\subsection{Goals}

The goal of my thesis research is to design and implement an abstract interface
using which the scientific computations on spatial meshes can be expressed
easily, at a high level, without having to consider or even know about the
characteristics of the hardware they are to run on or the data structures that
should be used to make the computations efficient. The abstraction is designed
in such a way that it is possible to automatically generate efficient,
high-performance code for multiple hardware architectures from the code written
using the abstraction.

The separation of the scientific code from the parallelisation and data
structure code provides a solution to the problem of scientists not being
computer experts as well as making it unnecessary to write code by hand for
different hardware architectures and maintaining all the versions. At the same
time, the use of code generation, together with the careful design of the
abstraction, makes it possible to run the computations with high performance.

The abstraction also frees the user from having to interact directly with the
data structures used in the computations. One of its main advantages is that the
data structures behind the interface can be replaced, which is important, as
different data structures may be optimal for different computations.

A critical extension to the model that is present in our abstraction in contrast
to existing frameworks is allowing multiple materials to be present at the same
grid point. This allows for more complex simulations and including this new
feature is the primary motivation behind this thesis research project.

\section{Existing solutions}

There are multiple frameworks that address the same or similar computation
models and challenges to the ones presented in this thesis. In this section, we
present two such frameworks: OPS \cite{OPS}, which can be used for computations
on structured meshes, and OP2 \cite{OP2}, which handles unstructured meshes.

\subsection{OPS}

\subsection{OP2}
OP2
- core vs. halo -- overlapping communication and computation
- colouring etc.

\chapter{Methods}

- DSLs (maybe from the OPS article also)?

\chapter{Presentation of the work}

\section{The abstraction}
\section{C++ implementation}
\section{Algorithms}
\section{Measurements?}

\chapter{Future work}

Codegen, CUDA, advection

\chapter{Conclusion}

\printbibliography
\appendix
\chapter{List of appendices}

\end{document}
